2025-08-24 06:17:29,053 [INFO] Starting new experiment: Person_Activity_Classifier_V1.0_20250824_061729
2025-08-24 06:17:29,055 [INFO] Using device: cuda. Seed: 42
2025-08-24 06:17:38,274 [INFO] Training dataset size: 2152
2025-08-24 06:17:38,275 [INFO] Validation dataset size: 1341
2025-08-24 06:17:38,277 [INFO] Starting training process
2025-08-24 06:17:38,277 [INFO] 
--- Epoch 1/8 ---
2025-08-24 06:17:43,701 [INFO] Epoch: 1 | Batch: 0/1076 | Loss: 2.2557 | Acc: 12.50%
2025-08-24 06:18:27,874 [INFO] Epoch: 1 | Batch: 50/1076 | Loss: 1.5194 | Acc: 36.11%
2025-08-24 06:19:11,932 [INFO] Epoch: 1 | Batch: 100/1076 | Loss: 0.6986 | Acc: 50.54%
2025-08-24 06:19:55,994 [INFO] Epoch: 1 | Batch: 150/1076 | Loss: 0.7520 | Acc: 56.29%
2025-08-24 06:20:40,052 [INFO] Epoch: 1 | Batch: 200/1076 | Loss: 1.0577 | Acc: 60.20%
2025-08-24 06:21:24,106 [INFO] Epoch: 1 | Batch: 250/1076 | Loss: 0.6657 | Acc: 62.65%
2025-08-24 06:22:08,167 [INFO] Epoch: 1 | Batch: 300/1076 | Loss: 0.8090 | Acc: 63.98%
2025-08-24 06:22:52,231 [INFO] Epoch: 1 | Batch: 350/1076 | Loss: 0.5809 | Acc: 65.37%
2025-08-24 06:23:36,282 [INFO] Epoch: 1 | Batch: 400/1076 | Loss: 1.0851 | Acc: 66.05%
2025-08-24 06:24:20,333 [INFO] Epoch: 1 | Batch: 450/1076 | Loss: 0.6216 | Acc: 66.98%
2025-08-24 06:25:04,389 [INFO] Epoch: 1 | Batch: 500/1076 | Loss: 1.1836 | Acc: 67.72%
2025-08-24 06:25:48,444 [INFO] Epoch: 1 | Batch: 550/1076 | Loss: 0.4208 | Acc: 68.25%
2025-08-24 06:26:32,497 [INFO] Epoch: 1 | Batch: 600/1076 | Loss: 1.2320 | Acc: 69.03%
2025-08-24 06:27:16,556 [INFO] Epoch: 1 | Batch: 650/1076 | Loss: 0.6132 | Acc: 69.83%
2025-08-24 06:28:00,624 [INFO] Epoch: 1 | Batch: 700/1076 | Loss: 0.5605 | Acc: 70.17%
2025-08-24 06:28:44,672 [INFO] Epoch: 1 | Batch: 750/1076 | Loss: 0.6008 | Acc: 70.53%
2025-08-24 06:29:28,732 [INFO] Epoch: 1 | Batch: 800/1076 | Loss: 0.5827 | Acc: 70.91%
2025-08-24 06:30:12,782 [INFO] Epoch: 1 | Batch: 850/1076 | Loss: 1.2139 | Acc: 71.30%
2025-08-24 06:30:56,834 [INFO] Epoch: 1 | Batch: 900/1076 | Loss: 0.4644 | Acc: 71.67%
2025-08-24 06:31:40,884 [INFO] Epoch: 1 | Batch: 950/1076 | Loss: 0.5193 | Acc: 72.05%
2025-08-24 06:32:24,947 [INFO] Epoch: 1 | Batch: 1000/1076 | Loss: 0.9908 | Acc: 72.34%
2025-08-24 06:33:09,007 [INFO] Epoch: 1 | Batch: 1050/1076 | Loss: 0.2909 | Acc: 72.62%
2025-08-24 06:33:31,093 [INFO] Epoch 1 | Train Loss: 0.8484 | Train Acc: 72.78%
2025-08-24 06:37:33,484 [INFO] Epoch 1 | Valid Loss: 0.6857 | Accuracy: 76.09% | F1 Score: 0.7361
2025-08-24 06:37:34,046 [INFO] New best validation accuracy: 76.09%! Saving model...
2025-08-24 06:37:35,020 [INFO] Current learning rate: 0.0001
2025-08-24 06:37:35,021 [INFO] 
--- Epoch 2/8 ---
2025-08-24 06:37:37,882 [INFO] Epoch: 2 | Batch: 0/1076 | Loss: 0.4528 | Acc: 83.33%
2025-08-24 06:38:21,963 [INFO] Epoch: 2 | Batch: 50/1076 | Loss: 0.3891 | Acc: 80.88%
2025-08-24 06:39:06,021 [INFO] Epoch: 2 | Batch: 100/1076 | Loss: 0.5380 | Acc: 80.78%
2025-08-24 06:39:50,085 [INFO] Epoch: 2 | Batch: 150/1076 | Loss: 0.5161 | Acc: 81.18%
2025-08-24 06:40:34,149 [INFO] Epoch: 2 | Batch: 200/1076 | Loss: 0.5566 | Acc: 81.22%
2025-08-24 06:41:18,212 [INFO] Epoch: 2 | Batch: 250/1076 | Loss: 0.3567 | Acc: 80.66%
2025-08-24 06:42:02,269 [INFO] Epoch: 2 | Batch: 300/1076 | Loss: 0.2298 | Acc: 80.59%
2025-08-24 06:42:46,322 [INFO] Epoch: 2 | Batch: 350/1076 | Loss: 0.2476 | Acc: 80.54%
2025-08-24 06:43:30,379 [INFO] Epoch: 2 | Batch: 400/1076 | Loss: 0.7148 | Acc: 80.48%
2025-08-24 06:44:14,449 [INFO] Epoch: 2 | Batch: 450/1076 | Loss: 0.5536 | Acc: 80.45%
2025-08-24 06:44:58,524 [INFO] Epoch: 2 | Batch: 500/1076 | Loss: 0.5486 | Acc: 80.48%
2025-08-24 06:45:42,586 [INFO] Epoch: 2 | Batch: 550/1076 | Loss: 0.4597 | Acc: 80.59%
2025-08-24 06:46:26,645 [INFO] Epoch: 2 | Batch: 600/1076 | Loss: 0.6557 | Acc: 80.60%
2025-08-24 06:47:10,706 [INFO] Epoch: 2 | Batch: 650/1076 | Loss: 0.6102 | Acc: 80.56%
2025-08-24 06:47:54,767 [INFO] Epoch: 2 | Batch: 700/1076 | Loss: 0.4645 | Acc: 80.52%
2025-08-24 06:48:38,815 [INFO] Epoch: 2 | Batch: 750/1076 | Loss: 0.4307 | Acc: 80.36%
2025-08-24 06:49:22,874 [INFO] Epoch: 2 | Batch: 800/1076 | Loss: 0.8908 | Acc: 80.39%
2025-08-24 06:50:06,927 [INFO] Epoch: 2 | Batch: 850/1076 | Loss: 0.7553 | Acc: 80.42%
2025-08-24 06:50:50,988 [INFO] Epoch: 2 | Batch: 900/1076 | Loss: 0.3815 | Acc: 80.50%
2025-08-24 06:51:35,054 [INFO] Epoch: 2 | Batch: 950/1076 | Loss: 0.2682 | Acc: 80.56%
2025-08-24 06:52:19,123 [INFO] Epoch: 2 | Batch: 1000/1076 | Loss: 0.3877 | Acc: 80.65%
2025-08-24 06:53:03,187 [INFO] Epoch: 2 | Batch: 1050/1076 | Loss: 0.8544 | Acc: 80.57%
2025-08-24 06:53:25,302 [INFO] Epoch 2 | Train Loss: 0.5647 | Train Acc: 80.43%
2025-08-24 06:57:07,966 [INFO] Epoch 2 | Valid Loss: 0.6492 | Accuracy: 76.67% | F1 Score: 0.7618
2025-08-24 06:57:08,447 [INFO] New best validation accuracy: 76.67%! Saving model...
2025-08-24 06:57:09,716 [INFO] Current learning rate: 0.0001
2025-08-24 06:57:09,717 [INFO] 
--- Epoch 3/8 ---
2025-08-24 06:57:12,322 [INFO] Epoch: 3 | Batch: 0/1076 | Loss: 0.3985 | Acc: 91.67%
2025-08-24 06:57:56,401 [INFO] Epoch: 3 | Batch: 50/1076 | Loss: 0.2352 | Acc: 83.82%
2025-08-24 06:58:40,462 [INFO] Epoch: 3 | Batch: 100/1076 | Loss: 1.2400 | Acc: 83.99%
2025-08-24 06:59:24,534 [INFO] Epoch: 3 | Batch: 150/1076 | Loss: 0.5647 | Acc: 83.94%
2025-08-24 07:00:08,596 [INFO] Epoch: 3 | Batch: 200/1076 | Loss: 0.9808 | Acc: 83.60%
2025-08-24 07:00:52,665 [INFO] Epoch: 3 | Batch: 250/1076 | Loss: 0.4127 | Acc: 83.98%
2025-08-24 07:01:36,724 [INFO] Epoch: 3 | Batch: 300/1076 | Loss: 0.4060 | Acc: 83.90%
2025-08-24 07:02:20,793 [INFO] Epoch: 3 | Batch: 350/1076 | Loss: 0.2651 | Acc: 84.13%
2025-08-24 07:03:04,875 [INFO] Epoch: 3 | Batch: 400/1076 | Loss: 0.6849 | Acc: 84.05%
2025-08-24 07:03:48,950 [INFO] Epoch: 3 | Batch: 450/1076 | Loss: 0.6461 | Acc: 83.73%
2025-08-24 07:04:33,018 [INFO] Epoch: 3 | Batch: 500/1076 | Loss: 0.4199 | Acc: 83.80%
2025-08-24 07:05:17,097 [INFO] Epoch: 3 | Batch: 550/1076 | Loss: 0.3063 | Acc: 83.71%
2025-08-24 07:06:01,177 [INFO] Epoch: 3 | Batch: 600/1076 | Loss: 0.7509 | Acc: 83.51%
2025-08-24 07:06:45,248 [INFO] Epoch: 3 | Batch: 650/1076 | Loss: 0.4273 | Acc: 83.47%
2025-08-24 07:07:29,329 [INFO] Epoch: 3 | Batch: 700/1076 | Loss: 0.4132 | Acc: 83.43%
2025-08-24 07:08:13,402 [INFO] Epoch: 3 | Batch: 750/1076 | Loss: 0.7115 | Acc: 83.40%
2025-08-24 07:08:57,473 [INFO] Epoch: 3 | Batch: 800/1076 | Loss: 0.1777 | Acc: 83.33%
2025-08-24 07:09:41,541 [INFO] Epoch: 3 | Batch: 850/1076 | Loss: 0.5094 | Acc: 83.33%
2025-08-24 07:10:25,622 [INFO] Epoch: 3 | Batch: 900/1076 | Loss: 0.5621 | Acc: 83.28%
2025-08-24 07:11:09,691 [INFO] Epoch: 3 | Batch: 950/1076 | Loss: 0.1579 | Acc: 83.22%
2025-08-24 07:11:53,757 [INFO] Epoch: 3 | Batch: 1000/1076 | Loss: 0.3302 | Acc: 83.42%
2025-08-24 07:12:37,833 [INFO] Epoch: 3 | Batch: 1050/1076 | Loss: 0.3359 | Acc: 83.27%
2025-08-24 07:12:59,930 [INFO] Epoch 3 | Train Loss: 0.4741 | Train Acc: 83.26%
2025-08-24 07:16:46,539 [INFO] Epoch 3 | Valid Loss: 0.6602 | Accuracy: 76.60% | F1 Score: 0.7637
2025-08-24 07:16:47,525 [INFO] Current learning rate: 0.0001
2025-08-24 07:16:47,526 [INFO] 
--- Epoch 4/8 ---
2025-08-24 07:16:50,537 [INFO] Epoch: 4 | Batch: 0/1076 | Loss: 0.2732 | Acc: 91.67%
2025-08-24 07:17:34,639 [INFO] Epoch: 4 | Batch: 50/1076 | Loss: 0.3173 | Acc: 88.56%
2025-08-24 07:18:18,721 [INFO] Epoch: 4 | Batch: 100/1076 | Loss: 0.3283 | Acc: 87.54%
2025-08-24 07:19:02,795 [INFO] Epoch: 4 | Batch: 150/1076 | Loss: 0.1534 | Acc: 87.80%
2025-08-24 07:19:46,871 [INFO] Epoch: 4 | Batch: 200/1076 | Loss: 0.2209 | Acc: 87.67%
2025-08-24 07:20:30,940 [INFO] Epoch: 4 | Batch: 250/1076 | Loss: 0.2119 | Acc: 87.37%
2025-08-24 07:21:15,013 [INFO] Epoch: 4 | Batch: 300/1076 | Loss: 0.7928 | Acc: 87.38%
2025-08-24 07:21:59,088 [INFO] Epoch: 4 | Batch: 350/1076 | Loss: 0.2314 | Acc: 87.36%
2025-08-24 07:22:43,158 [INFO] Epoch: 4 | Batch: 400/1076 | Loss: 0.4808 | Acc: 86.86%
2025-08-24 07:23:27,224 [INFO] Epoch: 4 | Batch: 450/1076 | Loss: 0.2886 | Acc: 86.77%
2025-08-24 07:24:11,302 [INFO] Epoch: 4 | Batch: 500/1076 | Loss: 0.3411 | Acc: 86.71%
2025-08-24 07:24:55,376 [INFO] Epoch: 4 | Batch: 550/1076 | Loss: 0.3507 | Acc: 86.51%
2025-08-24 07:25:39,450 [INFO] Epoch: 4 | Batch: 600/1076 | Loss: 0.1775 | Acc: 86.38%
2025-08-24 07:26:23,527 [INFO] Epoch: 4 | Batch: 650/1076 | Loss: 0.2112 | Acc: 86.44%
2025-08-24 07:27:07,615 [INFO] Epoch: 4 | Batch: 700/1076 | Loss: 0.2120 | Acc: 86.42%
2025-08-24 07:27:51,688 [INFO] Epoch: 4 | Batch: 750/1076 | Loss: 0.2006 | Acc: 86.38%
2025-08-24 07:28:35,758 [INFO] Epoch: 4 | Batch: 800/1076 | Loss: 0.7311 | Acc: 86.25%
2025-08-24 07:29:19,831 [INFO] Epoch: 4 | Batch: 850/1076 | Loss: 0.8825 | Acc: 86.20%
2025-08-24 07:30:03,901 [INFO] Epoch: 4 | Batch: 900/1076 | Loss: 0.3744 | Acc: 86.20%
2025-08-24 07:30:47,972 [INFO] Epoch: 4 | Batch: 950/1076 | Loss: 0.6274 | Acc: 86.08%
2025-08-24 07:31:32,042 [INFO] Epoch: 4 | Batch: 1000/1076 | Loss: 0.2184 | Acc: 86.02%
2025-08-24 07:32:16,127 [INFO] Epoch: 4 | Batch: 1050/1076 | Loss: 0.2601 | Acc: 85.95%
2025-08-24 07:32:38,229 [INFO] Epoch 4 | Train Loss: 0.3952 | Train Acc: 85.83%
2025-08-24 07:36:22,325 [INFO] Epoch 4 | Valid Loss: 0.6172 | Accuracy: 77.86% | F1 Score: 0.7712
2025-08-24 07:36:22,798 [INFO] New best validation accuracy: 77.86%! Saving model...
2025-08-24 07:36:24,098 [INFO] Current learning rate: 0.0001
2025-08-24 07:36:24,099 [INFO] 
--- Epoch 5/8 ---
2025-08-24 07:36:26,886 [INFO] Epoch: 5 | Batch: 0/1076 | Loss: 0.5051 | Acc: 87.50%
2025-08-24 07:37:10,981 [INFO] Epoch: 5 | Batch: 50/1076 | Loss: 0.5201 | Acc: 88.40%
2025-08-24 07:37:55,054 [INFO] Epoch: 5 | Batch: 100/1076 | Loss: 0.4525 | Acc: 89.69%
2025-08-24 07:38:39,118 [INFO] Epoch: 5 | Batch: 150/1076 | Loss: 0.3783 | Acc: 89.49%
2025-08-24 07:39:23,185 [INFO] Epoch: 5 | Batch: 200/1076 | Loss: 0.2019 | Acc: 89.53%
2025-08-24 07:40:07,267 [INFO] Epoch: 5 | Batch: 250/1076 | Loss: 0.8850 | Acc: 89.58%
2025-08-24 07:40:51,357 [INFO] Epoch: 5 | Batch: 300/1076 | Loss: 0.2281 | Acc: 89.77%
2025-08-24 07:41:35,433 [INFO] Epoch: 5 | Batch: 350/1076 | Loss: 0.2212 | Acc: 89.35%
2025-08-24 07:42:19,508 [INFO] Epoch: 5 | Batch: 400/1076 | Loss: 0.2604 | Acc: 89.24%
2025-08-24 07:43:03,584 [INFO] Epoch: 5 | Batch: 450/1076 | Loss: 0.0870 | Acc: 89.33%
2025-08-24 07:43:47,677 [INFO] Epoch: 5 | Batch: 500/1076 | Loss: 0.6201 | Acc: 89.09%
2025-08-24 07:44:31,758 [INFO] Epoch: 5 | Batch: 550/1076 | Loss: 0.2800 | Acc: 88.90%
2025-08-24 07:45:15,827 [INFO] Epoch: 5 | Batch: 600/1076 | Loss: 0.8849 | Acc: 88.75%
2025-08-24 07:45:59,894 [INFO] Epoch: 5 | Batch: 650/1076 | Loss: 0.2872 | Acc: 88.75%
2025-08-24 07:46:43,973 [INFO] Epoch: 5 | Batch: 700/1076 | Loss: 0.1483 | Acc: 88.69%
2025-08-24 07:47:28,064 [INFO] Epoch: 5 | Batch: 750/1076 | Loss: 0.2789 | Acc: 88.51%
2025-08-24 07:48:12,139 [INFO] Epoch: 5 | Batch: 800/1076 | Loss: 0.7934 | Acc: 88.56%
2025-08-24 07:48:56,221 [INFO] Epoch: 5 | Batch: 850/1076 | Loss: 0.7057 | Acc: 88.50%
2025-08-24 07:49:40,293 [INFO] Epoch: 5 | Batch: 900/1076 | Loss: 0.6398 | Acc: 88.44%
2025-08-24 07:50:24,379 [INFO] Epoch: 5 | Batch: 950/1076 | Loss: 0.1445 | Acc: 88.44%
2025-08-24 07:51:08,443 [INFO] Epoch: 5 | Batch: 1000/1076 | Loss: 0.7932 | Acc: 88.46%
2025-08-24 07:51:52,516 [INFO] Epoch: 5 | Batch: 1050/1076 | Loss: 0.3861 | Acc: 88.44%
2025-08-24 07:52:14,626 [INFO] Epoch 5 | Train Loss: 0.3221 | Train Acc: 88.46%
2025-08-24 07:55:58,757 [INFO] Epoch 5 | Valid Loss: 0.6722 | Accuracy: 77.74% | F1 Score: 0.7727
2025-08-24 07:55:59,717 [INFO] Current learning rate: 0.0001
2025-08-24 07:55:59,718 [INFO] 
--- Epoch 6/8 ---
2025-08-24 07:56:02,671 [INFO] Epoch: 6 | Batch: 0/1076 | Loss: 0.1200 | Acc: 100.00%
2025-08-24 07:56:46,754 [INFO] Epoch: 6 | Batch: 50/1076 | Loss: 0.5251 | Acc: 90.52%
2025-08-24 07:57:30,830 [INFO] Epoch: 6 | Batch: 100/1076 | Loss: 0.4491 | Acc: 91.42%
2025-08-24 07:58:14,902 [INFO] Epoch: 6 | Batch: 150/1076 | Loss: 0.3139 | Acc: 92.14%
2025-08-24 07:58:58,977 [INFO] Epoch: 6 | Batch: 200/1076 | Loss: 0.1074 | Acc: 92.56%
2025-08-24 07:59:43,052 [INFO] Epoch: 6 | Batch: 250/1076 | Loss: 0.4398 | Acc: 92.36%
2025-08-24 08:00:27,127 [INFO] Epoch: 6 | Batch: 300/1076 | Loss: 0.2922 | Acc: 92.40%
2025-08-24 08:01:11,207 [INFO] Epoch: 6 | Batch: 350/1076 | Loss: 0.0424 | Acc: 92.22%
2025-08-24 08:01:55,292 [INFO] Epoch: 6 | Batch: 400/1076 | Loss: 0.2548 | Acc: 91.80%
2025-08-24 08:02:39,378 [INFO] Epoch: 6 | Batch: 450/1076 | Loss: 0.4630 | Acc: 91.51%
2025-08-24 08:03:23,485 [INFO] Epoch: 6 | Batch: 500/1076 | Loss: 0.1687 | Acc: 91.46%
2025-08-24 08:04:07,570 [INFO] Epoch: 6 | Batch: 550/1076 | Loss: 0.1543 | Acc: 91.59%
2025-08-24 08:04:51,642 [INFO] Epoch: 6 | Batch: 600/1076 | Loss: 0.1723 | Acc: 91.72%
2025-08-24 08:05:35,714 [INFO] Epoch: 6 | Batch: 650/1076 | Loss: 0.0851 | Acc: 91.69%
2025-08-24 08:06:19,793 [INFO] Epoch: 6 | Batch: 700/1076 | Loss: 0.2784 | Acc: 91.58%
2025-08-24 08:07:03,879 [INFO] Epoch: 6 | Batch: 750/1076 | Loss: 0.1473 | Acc: 91.44%
2025-08-24 08:07:47,961 [INFO] Epoch: 6 | Batch: 800/1076 | Loss: 0.1985 | Acc: 91.39%
2025-08-24 08:08:32,028 [INFO] Epoch: 6 | Batch: 850/1076 | Loss: 0.4163 | Acc: 91.40%
2025-08-24 08:09:16,097 [INFO] Epoch: 6 | Batch: 900/1076 | Loss: 0.9832 | Acc: 91.30%
2025-08-24 08:10:00,166 [INFO] Epoch: 6 | Batch: 950/1076 | Loss: 0.2525 | Acc: 91.15%
2025-08-24 08:10:44,238 [INFO] Epoch: 6 | Batch: 1000/1076 | Loss: 0.1456 | Acc: 90.93%
2025-08-24 08:11:28,320 [INFO] Epoch: 6 | Batch: 1050/1076 | Loss: 0.1963 | Acc: 90.83%
2025-08-24 08:11:50,425 [INFO] Epoch 6 | Train Loss: 0.2492 | Train Acc: 90.80%
2025-08-24 08:15:33,555 [INFO] Epoch 6 | Valid Loss: 0.7200 | Accuracy: 78.74% | F1 Score: 0.7754
2025-08-24 08:15:34,038 [INFO] New best validation accuracy: 78.74%! Saving model...
2025-08-24 08:15:35,339 [INFO] Current learning rate: 0.0001
2025-08-24 08:15:35,340 [INFO] 
--- Epoch 7/8 ---
2025-08-24 08:15:38,092 [INFO] Epoch: 7 | Batch: 0/1076 | Loss: 0.1716 | Acc: 95.83%
2025-08-24 08:16:22,191 [INFO] Epoch: 7 | Batch: 50/1076 | Loss: 0.0918 | Acc: 92.81%
2025-08-24 08:17:06,276 [INFO] Epoch: 7 | Batch: 100/1076 | Loss: 0.1311 | Acc: 93.56%
2025-08-24 08:17:50,363 [INFO] Epoch: 7 | Batch: 150/1076 | Loss: 0.2421 | Acc: 93.96%
2025-08-24 08:18:34,436 [INFO] Epoch: 7 | Batch: 200/1076 | Loss: 0.3782 | Acc: 93.97%
2025-08-24 08:19:18,521 [INFO] Epoch: 7 | Batch: 250/1076 | Loss: 0.0672 | Acc: 94.14%
2025-08-24 08:20:02,593 [INFO] Epoch: 7 | Batch: 300/1076 | Loss: 0.0531 | Acc: 93.92%
2025-08-24 08:20:46,664 [INFO] Epoch: 7 | Batch: 350/1076 | Loss: 0.1289 | Acc: 93.92%
2025-08-24 08:21:30,745 [INFO] Epoch: 7 | Batch: 400/1076 | Loss: 0.1730 | Acc: 94.06%
2025-08-24 08:22:14,828 [INFO] Epoch: 7 | Batch: 450/1076 | Loss: 0.3388 | Acc: 93.95%
2025-08-24 08:22:58,911 [INFO] Epoch: 7 | Batch: 500/1076 | Loss: 0.1515 | Acc: 93.85%
2025-08-24 08:23:42,993 [INFO] Epoch: 7 | Batch: 550/1076 | Loss: 0.3298 | Acc: 93.61%
2025-08-24 08:24:27,071 [INFO] Epoch: 7 | Batch: 600/1076 | Loss: 0.1057 | Acc: 93.52%
2025-08-24 08:25:11,144 [INFO] Epoch: 7 | Batch: 650/1076 | Loss: 0.3383 | Acc: 93.46%
2025-08-24 08:25:55,218 [INFO] Epoch: 7 | Batch: 700/1076 | Loss: 0.0516 | Acc: 93.48%
2025-08-24 08:26:39,289 [INFO] Epoch: 7 | Batch: 750/1076 | Loss: 0.3884 | Acc: 93.51%
2025-08-24 08:27:23,365 [INFO] Epoch: 7 | Batch: 800/1076 | Loss: 0.0959 | Acc: 93.48%
2025-08-24 08:28:07,453 [INFO] Epoch: 7 | Batch: 850/1076 | Loss: 0.3574 | Acc: 93.42%
2025-08-24 08:28:51,529 [INFO] Epoch: 7 | Batch: 900/1076 | Loss: 0.0722 | Acc: 93.30%
2025-08-24 08:29:35,616 [INFO] Epoch: 7 | Batch: 950/1076 | Loss: 0.1453 | Acc: 93.23%
2025-08-24 08:30:19,704 [INFO] Epoch: 7 | Batch: 1000/1076 | Loss: 0.2243 | Acc: 93.20%
2025-08-24 08:31:03,781 [INFO] Epoch: 7 | Batch: 1050/1076 | Loss: 0.0996 | Acc: 93.12%
2025-08-24 08:31:25,891 [INFO] Epoch 7 | Train Loss: 0.1832 | Train Acc: 93.11%
2025-08-24 08:35:11,480 [INFO] Epoch 7 | Valid Loss: 0.8545 | Accuracy: 76.19% | F1 Score: 0.7516
2025-08-24 08:35:12,420 [INFO] Current learning rate: 0.0001
2025-08-24 08:35:12,421 [INFO] 
--- Epoch 8/8 ---
2025-08-24 08:35:15,391 [INFO] Epoch: 8 | Batch: 0/1076 | Loss: 0.2985 | Acc: 83.33%
2025-08-24 08:35:59,492 [INFO] Epoch: 8 | Batch: 50/1076 | Loss: 0.1598 | Acc: 94.93%
2025-08-24 08:36:43,572 [INFO] Epoch: 8 | Batch: 100/1076 | Loss: 0.1050 | Acc: 94.88%
2025-08-24 08:37:27,647 [INFO] Epoch: 8 | Batch: 150/1076 | Loss: 0.0659 | Acc: 95.28%
2025-08-24 08:38:11,721 [INFO] Epoch: 8 | Batch: 200/1076 | Loss: 0.1894 | Acc: 95.46%
2025-08-24 08:38:55,799 [INFO] Epoch: 8 | Batch: 250/1076 | Loss: 0.1500 | Acc: 95.48%
2025-08-24 08:39:39,882 [INFO] Epoch: 8 | Batch: 300/1076 | Loss: 0.4349 | Acc: 95.07%
2025-08-24 08:40:23,969 [INFO] Epoch: 8 | Batch: 350/1076 | Loss: 0.3655 | Acc: 94.97%
2025-08-24 08:41:08,047 [INFO] Epoch: 8 | Batch: 400/1076 | Loss: 0.1653 | Acc: 94.99%
2025-08-24 08:41:52,129 [INFO] Epoch: 8 | Batch: 450/1076 | Loss: 0.0463 | Acc: 95.06%
2025-08-24 08:42:36,215 [INFO] Epoch: 8 | Batch: 500/1076 | Loss: 0.0816 | Acc: 94.94%
2025-08-24 08:43:20,299 [INFO] Epoch: 8 | Batch: 550/1076 | Loss: 0.0415 | Acc: 94.99%
2025-08-24 08:44:04,380 [INFO] Epoch: 8 | Batch: 600/1076 | Loss: 0.0679 | Acc: 94.95%
2025-08-24 08:44:48,454 [INFO] Epoch: 8 | Batch: 650/1076 | Loss: 0.0641 | Acc: 94.87%
2025-08-24 08:45:32,531 [INFO] Epoch: 8 | Batch: 700/1076 | Loss: 0.1234 | Acc: 94.83%
2025-08-24 08:46:16,609 [INFO] Epoch: 8 | Batch: 750/1076 | Loss: 0.1005 | Acc: 94.78%
2025-08-24 08:47:00,695 [INFO] Epoch: 8 | Batch: 800/1076 | Loss: 0.1923 | Acc: 94.71%
2025-08-24 08:47:44,776 [INFO] Epoch: 8 | Batch: 850/1076 | Loss: 0.7350 | Acc: 94.73%
2025-08-24 08:48:28,862 [INFO] Epoch: 8 | Batch: 900/1076 | Loss: 0.0655 | Acc: 94.62%
2025-08-24 08:49:12,940 [INFO] Epoch: 8 | Batch: 950/1076 | Loss: 0.2352 | Acc: 94.65%
2025-08-24 08:49:57,021 [INFO] Epoch: 8 | Batch: 1000/1076 | Loss: 0.1785 | Acc: 94.66%
2025-08-24 08:50:41,101 [INFO] Epoch: 8 | Batch: 1050/1076 | Loss: 0.1184 | Acc: 94.57%
2025-08-24 08:51:03,209 [INFO] Epoch 8 | Train Loss: 0.1507 | Train Acc: 94.52%
2025-08-24 08:54:44,863 [INFO] Epoch 8 | Valid Loss: 0.9166 | Accuracy: 73.27% | F1 Score: 0.7445
2025-08-24 08:54:45,822 [INFO] Current learning rate: 0.0001
2025-08-24 08:54:45,823 [INFO] Training completed successfully.
